{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Shahwaiz\n",
    "----\n",
    "## Goal\n",
    "\n",
    "Your goal in this part of assigment is to implement a Decision Tree Classifier for categorical variables.\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Now in this assignment we will be implementing the Decision Classifier for both Continuous and Categorical attributes.\n",
    "\n",
    "Decision tree can be built by using any of the following split criterias, namely:\n",
    " - Information Gain\n",
    " - Gini Index\n",
    " - CART \n",
    "\n",
    "However, you are required here to implement the decision tree with information gain as splitting criterion.\n",
    "\n",
    "Remember in my code i am not looking for maximizing the information gain, instead i am looking for minimizing the split entropy. Recall,\n",
    "$$Information Gain  = H(D) - H(D_Y,D_N)$$\n",
    "\n",
    "Where,\n",
    "\n",
    "$H(D)$ is the data set entroy and $H(D_Y,D_N)$ is split entropy. Since $H(D)$ is constant for the given dataset so maximizing the entropy is equal to minimizing the split entropy and that is what is being represented in my code outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Cutomize the Matplotlib for beautiful plots...\n",
    "# import dmStyle\n",
    "# dmStyle.customize_mpl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t # set of tools for plotting, data splitting, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSplits(categories):\n",
    "    '''\n",
    "        function returns list of splits for the given list of categorical variables...\n",
    "        \n",
    "        Input:\n",
    "        ------------\n",
    "            categories: a list of unique categories...\n",
    "        \n",
    "        Return:\n",
    "        ------------\n",
    "            list of splits(tuples) for given list of categorical variables. Each pair of sublists\n",
    "            defines the left and right splits, e.g. This list\n",
    "            [('y', 'f'), ('s', 'g'), ('f'), ('y', 's', 'g')]\n",
    "            \n",
    "            defines two splits with each pair representing a different split.\n",
    "        Examples:\n",
    "        ------------\n",
    "        splits=getSplits(['a1','a2','a3','a4']) will return \n",
    "        [('a1', 'a2', 'a4'), ('a3',), ('a2', 'a4'), \n",
    "        ('a1', 'a3'), ('a1', 'a4'), ('a3', 'a2'), ('a1', 'a3', 'a2'), \n",
    "        ('a4',), ('a3', 'a4'), ('a1', 'a2'), ('a1',), ('a3', 'a2', 'a4'), ('a2',), ('a1', 'a3', 'a4')]\n",
    "\n",
    "            \n",
    "    '''\n",
    "    categories=set(categories)\n",
    "    tsplits=t.get_powerset(categories,len(categories)-1) # get all the power sets with the given cardinality...\n",
    "    flist=[]\n",
    "    for s in tsplits:\n",
    "\n",
    "        if not s in flist:\n",
    "            r=categories.difference(s)\n",
    "    #         print s, tuple(r)\n",
    "            flist.append(s)\n",
    "            flist.append(r)\n",
    "\n",
    "    olist=[]\n",
    "\n",
    "    for s in flist:\n",
    "        ilist=[]\n",
    "\n",
    "        for k in s:\n",
    "            ilist.append(k)\n",
    "        olist.append(tuple(ilist))\n",
    "\n",
    "#     print olist\n",
    "    \n",
    "    return olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a1', 'a2', 'a4'), ('a3',), ('a2', 'a4'), ('a1', 'a3'), ('a1', 'a4'), ('a3', 'a2'), ('a1', 'a3', 'a2'), ('a4',), ('a3', 'a4'), ('a1', 'a2'), ('a1',), ('a3', 'a2', 'a4'), ('a2',), ('a1', 'a3', 'a4')] 14\n"
     ]
    }
   ],
   "source": [
    "splits=getSplits( [ 'a1','a2','a3','a4'] )\n",
    "print splits,len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9b51b07ea3a13ec3397e850394a4f376",
     "grade": false,
     "grade_id": "node",
     "locked": false,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        '''\n",
    "            purity: purity level at which to stop\n",
    "            klasslabel: klasslabel of the node, (for leaf node)\n",
    "            score: information gain of the newly added node\n",
    "            split: splitting threshold\n",
    "            fidx: feature index            \n",
    "        '''\n",
    "        self.lchild=None\n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        self.ftype= 'categorical' if type(self.split) in [tuple, str, numpy.string_] else 'continuous' # feature type \n",
    "\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    def isleaf(self):\n",
    "        # YOUR CODE HERE\n",
    "        if(self.lchild is  None and self.rchild is  None):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        #raise NotImplementedError()\n",
    "    def isless_than_eq(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A placeholder class \n",
    "# TODO: You have to implement the following class, remember from the lectures that you will \n",
    "# need to build a model for each different class you are trying to identify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8cf330276474635d74a097faf9634f52",
     "grade": false,
     "grade_id": "tree",
     "locked": false,
     "solution": true
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### import pdb\n",
    "## Your code goes here...\n",
    "# You might need to define auxliary classes for composition.. ?\n",
    "#DecisionTree\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold, maxdepth=10):        \n",
    "        self.purity = purityp\n",
    "        self.exthreshold = exthreshold\n",
    "        self.maxdepth = maxdepth\n",
    "        self.root=None\n",
    "        pass\n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        #nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        #Xc=copy.copy(X)\n",
    "        #Yc=copy.copy(Y)\n",
    "        self.build_tree(X,Y,3)\n",
    "        return \n",
    "       \n",
    "    def build_tree(self, X, Y, depth,currNode=None):\n",
    "            \"\"\" \n",
    "                Function is used to recursively build the decision Tree \n",
    "\n",
    "                Input\n",
    "                -----\n",
    "                X: [m x d] a data matrix of m d-dimensional examples.\n",
    "                Y: [m x 1] a label vector.\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                root node of the built tree...\n",
    "            \"\"\"\n",
    "            \n",
    "            if(X.size==0):\n",
    "                currNode=None\n",
    "                return \n",
    "            \n",
    "            #print \"Y::\",np.count_nonzero(Y=='f')\n",
    "            #print \"X::\",X\n",
    "            nexamples, nfeatures=X.shape\n",
    "            #if(self.find_depth()>=10 ):\n",
    "                #return self.root     \n",
    "            #if(Y.size==0):\n",
    "                #return \n",
    "            klasses=np.unique(Y)\n",
    "            # YOUR CODE HERE\n",
    "            p_arr=[]\n",
    "            argmax_flag=False\n",
    "            for i in klasses:\n",
    "                    argmax_flag=True\n",
    "                    p_arr.append( X[Y==i].shape[0])#/float(nexamples) )\n",
    "            \n",
    "            p_idx=np.argmax(p_arr)\n",
    "            purityD=p_arr[p_idx]/float(nexamples)\n",
    "            #print \"purityD::\",purityD\n",
    "            if (nexamples<=self.exthreshold or purityD>=self.purity or self.find_depth()>6):\n",
    "                \n",
    "                currNode.purity=purityD\n",
    "                currNode.klasslabel=klasses[p_idx]\n",
    "                \n",
    "                \n",
    "                currNode.lchild=None\n",
    "                currNode.rchild=None\n",
    "                return self.root    \n",
    "            split_point=None\n",
    "            score=100\n",
    "            \n",
    "            Xlidx=[]\n",
    "            Xridx=[]\n",
    "            bestFeat=-1\n",
    "            \n",
    "            #X=X.T\n",
    "            for feat in range(X.shape[1]):\n",
    "                #def evaluate_numerical_attribute(self,feat, Y)\n",
    "                #print \"feat:\",feat\n",
    "                split,mingain_score,tmpXlidx,tmpXridx = self.evaluate_categorical_attribute(X[:,feat], Y)\n",
    "                if(mingain_score < score):  \n",
    "                    #print \"split:\",split\n",
    "                    split_point=split\n",
    "                    score=mingain_score\n",
    "                    Xlidx=tmpXlidx\n",
    "                    Xridx=tmpXridx\n",
    "                    bestFeat=feat\n",
    "            ###now we have the best split point for best feature\n",
    "            ###split the X into two parts Dy and Dn on basis of split point\n",
    "            ###Book:// partition D into DY and DN using split point∗, and call recursively \n",
    "            \n",
    "            #print \"split_store:\",bestFeat,split_point\n",
    "            DY_exp=X[ Xlidx ]\n",
    "            DN_exp=X[ Xridx ]\n",
    "            Y_l=Y[ Xlidx ]\n",
    "            Y_r=Y[ Xridx ]\n",
    "            #print \"Xlidx:\",Xlidx\n",
    "            #print \"Xridx:\",Xridx\n",
    "            \n",
    "            ###***********************************************************###\n",
    "            #################################################################\n",
    "            ###def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "            \n",
    "            split_store=[ bestFeat,split_point]\n",
    "            #print \"split_store::\",split_store\n",
    "            if(self.root==None):\n",
    "                \n",
    "                self.root=Node(purityD,'',score,split_store,-1)\n",
    "                self.root.lchild=Node(-1,'noclass',-1,[-1,-1],-1)\n",
    "                self.root.rchild=Node(-1,'noclass',-1,[-1,-1],-1)\n",
    "                \n",
    "                self.build_tree(DY_exp,Y_l,10,self.root.lchild)\n",
    "                self.build_tree(DN_exp,Y_r,10,self.root.rchild)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                currNode.purity=purityD\n",
    "                currNode.klasslabel=''\n",
    "                currNode.score=score\n",
    "                currNode.split=split_store\n",
    "                currNode.fidx=-1\n",
    "                \n",
    "                currNode.lchild=Node(-1,'noclass',-1,[-1,-1],-1)\n",
    "                currNode.rchild=Node(-1,'noclass',-1,[-1,-1],-1)\n",
    "                \n",
    "                self.build_tree(DY_exp,Y_l,10,currNode.lchild)\n",
    "                self.build_tree(DN_exp,Y_r,10,currNode.rchild)\n",
    "                \n",
    "            return\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        \n",
    "        nexamples, nfeatures = X.shape\n",
    "        pclasses = self.predict(X)\n",
    "        \n",
    "        # your code go here...\n",
    "        \n",
    "        return np.array(pclasses)\n",
    "    def evaluate_categorical_attribute(self, feat, Y):\n",
    "            \"\"\"\n",
    "            Evaluates the cateogrical attribute for all possible split points, i.e. 2^(m-1)-2 for\n",
    "            possible feature selection\n",
    "\n",
    "            Input:\n",
    "            ---------\n",
    "            feat: a categorical feature\n",
    "            Y: labels\n",
    "\n",
    "            Returns:\n",
    "            ----------\n",
    "            v: splitting threshold\n",
    "            score: splitting score\n",
    "            Xlidx: Index of examples belonging to left child node\n",
    "            Xridx: Index of examples belonging to right child node\n",
    "\n",
    "            \"\"\"\n",
    "            categories = set(feat)\n",
    "            splits = getSplits(categories) if len(categories) > 1 else tuple(categories)\n",
    "            #freq = scipy.stats.itemfreq(Y)\n",
    "            ############################################\n",
    "            #******************************************#\n",
    "            # YOUR CODE HERE\n",
    "            ###calcculate the entropy and return it\n",
    "            klasses=np.unique(Y)\n",
    "            splits_entrop=[]\n",
    "            \n",
    "            sz_tot=float(Y.shape[0])   \n",
    "            for s in splits:\n",
    "                    idx=np.in1d(feat,s).nonzero()[0]\n",
    "                    idxv=np.in1d(feat,s,invert=True).nonzero()[0]\n",
    "                    \n",
    "                    s_y = Y[idx]\n",
    "                    s_n = Y[idxv]\n",
    "                    \n",
    "                    p_y=s_y.shape[0] / sz_tot\n",
    "                    p_n=s_n.shape[0] / sz_tot\n",
    "                    \n",
    "                    \n",
    "                    size_y=float(s_y.shape[0])\n",
    "                    size_n=float(s_n.shape[0])\n",
    "                    \n",
    "                    h_d_x=0.0\n",
    "                    h_d_n=0.0\n",
    "                        \n",
    "                    for k in klasses:\n",
    "                        \n",
    "                        p = s_y[s_y==k].shape[0]/size_y\n",
    "                        \n",
    "                        tmp=p * np.log2( p + np.spacing(1) )\n",
    "                        \n",
    "                        h_d_x = h_d_x + tmp\n",
    "             \n",
    "                        if(size_n!=0):\n",
    "                            p2=s_n[s_n==k].shape[0]/size_n\n",
    "                        else:\n",
    "                            p2=0.0\n",
    "                        h_d_n=  h_d_n + p2 * np.log2( p2 + np.spacing(1) )\n",
    "                    \n",
    "                    h_d_n=h_d_n*-1\n",
    "                    h_d_x=h_d_x*-1\n",
    "                    #Now cal the Entropy for (s,Universe-s) # s is from splits array\n",
    "                    entrop= (p_n * h_d_n) + (p_y * h_d_x)\n",
    "                    #print \"entrop::\",entrop\n",
    "                    if(entrop!=0 and entrop is not nan):\n",
    "                        splits_entrop.append(entrop)    \n",
    "                    else:\n",
    "                        splits_entrop.append(100)\n",
    "                        \n",
    "            ###now we have the min entrop and the split point which gives the min entrop \n",
    "            \n",
    "            bidx=np.argmin(splits_entrop)\n",
    "            csplit=splits[bidx]\n",
    "            mingain=splits_entrop[bidx]\n",
    "            \n",
    "            Xlidx=np.in1d(feat,csplit).nonzero()[0]#points that satisfy the split point \n",
    "            Xridx=np.in1d(feat,csplit,invert=True).nonzero()[0]        \n",
    " \n",
    "            \n",
    "            #******************************************#\n",
    "            ############################################\n",
    "            \n",
    "            #raise NotImplementedError()\n",
    "            return csplit, mingain, Xlidx, Xridx\n",
    "        \n",
    "    def evaluate_numerical_attribute(self, feat, Y):\n",
    "        '''\n",
    "            Evaluates the numerical attribute for all possible split points for\n",
    "            possible feature selection\n",
    "            \n",
    "            Input:\n",
    "            ---------\n",
    "            feat: a contiuous feature\n",
    "            Y: labels\n",
    "            \n",
    "            Returns:\n",
    "            ----------\n",
    "            v: splitting threshold\n",
    "            score: splitting score\n",
    "            Xlidx: Index of examples belonging to left child node\n",
    "            Xridx: Index of examples belonging to right child node\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        classes = np.unique(Y)\n",
    "        nclasses = len(self.classes)\n",
    "        f = np.sort(feat)\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return split, mingain, Xlidx, Xridx\n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Test the trained classifiers on the given example X\n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [1 x d] a d-dimensional test example.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for the given example, i.e. to which it belongs\n",
    "        \"\"\"\n",
    "        z = []\n",
    "        \n",
    "        for idx in range(X.shape[0]):\n",
    "            \n",
    "            z.append(self._predict(self.root, X[idx, :]))\n",
    "        \n",
    "        return z \n",
    "    \n",
    "    def _predict(self, node, X):\n",
    "        #[ bestFeat,split_point]\n",
    "        # YOUR CODE HERE\n",
    "        if( node.lchild == None or node.rchild == None):\n",
    "            return node.klasslabel\n",
    "        else:\n",
    "            bFeat=node.split[0]\n",
    "            val=node.split[1]\n",
    "            \n",
    "            #Xlidx=np.in1d(X , csplit).nonzero()[0]#points that satisfy the split point \n",
    "            \n",
    "            #Xridx=np.in1d(feat,csplit,invert=True).nonzero()[0]        \n",
    "            l_flag=False\n",
    "            for i in val:\n",
    "                if(i==X[bFeat]):\n",
    "                    l_flag=True\n",
    "            if( l_flag ):\n",
    "                return self._predict(node.lchild,X)\n",
    "            else:\n",
    "                return self._predict(node.rchild,X)\n",
    "        \n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def __str__(self):\n",
    "        str = '---------------------------------------------------'\n",
    "        str += '\\n A Decision Tree With Depth={}'.format(self.find_depth())\n",
    "        str += self.__print(self.root)\n",
    "        str += '\\n---------------------------------------------------'\n",
    "        return str  # self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "   \n",
    "    def find_depth(self):\n",
    "        return self._find_depth(self.root)\n",
    "    def _find_depth(self, node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild), self._find_depth(node.rchild)) + 1\n",
    "    def __print(self, node, depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild, depth + 1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild, depth + 1)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier two features\n",
    "#%pdb\n",
    "feat=np.arange(2)\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test our code for the given example in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('a1',) 0.510702350316\n"
     ]
    }
   ],
   "source": [
    "#%pdb off\n",
    "#dt=DecisionTree(0.95,5,5)\n",
    "split, gain, Xlidx, Xridx = evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "#q,e,r,p=evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "print \n",
    "print split, gain\n",
    "#Automatic pdb calling has been turned OFF\n",
    "#('a1',) 0.510702350316\n",
    "#h_d_y=0.991\n",
    "#h_d_n=0.673\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the Iris dataset\n",
    "tdata=pd.read_csv('./iris.data')\n",
    "tdata.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (8124L, 22L)  True Class labels dimensions (8124L,)\n",
      " Training Data Set Dimensions= (5687L, 22L) Training True Class labels dimensions (5687L,)\n",
      " Test Data Set Dimensions= (2437L, 22L) Test True Class labels dimensions (5687L,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix\n",
    "X=np.asarray(data.ix[:,1:].dropna())\n",
    "Y=np.asarray(data.ix[:,0].dropna())\n",
    "print \" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape   \n",
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   \n",
    "\n",
    "\n",
    "from nose.tools import assert_greater_equal\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "feat=np.arange(2)\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "\n",
    "\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "\n",
    "assert_greater_equal(acc, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tx=tdata['SepalLength'].dropna()\n",
    "\n",
    "tx[(tdata['SepalLength']>=4.3) & (tdata['SepalLength']<=5.2)]='a1'\n",
    "tx[(tdata['SepalLength']>5.2) & (tdata['SepalLength']<=6.1)]='a2'\n",
    "tx[(tdata['SepalLength']>6.1) & (tdata['SepalLength']<=7.0)]='a3'\n",
    "tx[(tdata['SepalLength']>7.0) & (tdata['SepalLength']<=7.9)]='a4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1' 'a1' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a2' 'a2'\n",
      " 'a2' 'a1' 'a2' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1'\n",
      " 'a2' 'a1' 'a2' 'a1' 'a1' 'a2' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1' 'a1'\n",
      " 'a1' 'a1' 'a2' 'a1' 'a3' 'a3' 'a3' 'a2' 'a3' 'a2' 'a3' 'a1' 'a3' 'a1' 'a1'\n",
      " 'a2' 'a2' 'a2' 'a2' 'a3' 'a2' 'a2' 'a3' 'a2' 'a2' 'a2' 'a3' 'a2' 'a3' 'a3'\n",
      " 'a3' 'a3' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a2' 'a3' 'a3' 'a2' 'a2' 'a2'\n",
      " 'a2' 'a2' 'a1' 'a2' 'a2' 'a2' 'a3' 'a1' 'a2' 'a3' 'a2' 'a4' 'a3' 'a3' 'a4'\n",
      " 'a1' 'a4' 'a3' 'a4' 'a3' 'a3' 'a3' 'a2' 'a2' 'a3' 'a3' 'a4' 'a4' 'a2' 'a3'\n",
      " 'a2' 'a4' 'a3' 'a3' 'a4' 'a3' 'a2' 'a3' 'a4' 'a4' 'a4' 'a3' 'a3' 'a2' 'a4'\n",
      " 'a3' 'a3' 'a2' 'a3' 'a3' 'a3' 'a2' 'a3' 'a3' 'a3' 'a3' 'a3' 'a3' 'a2']\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "print tx.values\n",
    "Y=tdata['Class'].dropna()\n",
    "Y[Y=='Iris-virginica']='Iris-versicolor'\n",
    "Y=Y.values\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['a1', 'a3', 'a2', 'a4'])\n"
     ]
    }
   ],
   "source": [
    "categories = set(tx)\n",
    "print categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('a1',) 0.510702350316\n"
     ]
    }
   ],
   "source": [
    "#%pdb off\n",
    "dt=DecisionTree(0.95,5,5)\n",
    "split, gain, Xlidx, Xridx = dt.evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "#q,e,r,p=evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "print \n",
    "print split, gain\n",
    "#Automatic pdb calling has been turned OFF\n",
    "#('a1',) 0.510702350316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "084088885dd9b2a201b9d9cfca1525cb",
     "grade": true,
     "grade_id": "split_gain",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_almost_equal, assert_almost_equals\n",
    "\n",
    "%pdb off\n",
    "dt=DecisionTree(0.95,5,5)\n",
    "split, gain, Xlidx, Xridx = dt.evaluate_categorical_attribute(tx,Y)\n",
    "\n",
    "\n",
    "assert_almost_equal('a1', split[0])\n",
    "assert_almost_equal(gain, 0.51, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets test on [Mushroom](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.names) dataset\n",
    "\n",
    "\n",
    "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.\n",
    "\n",
    "\n",
    "- Number of Instances: 8124\n",
    "\n",
    "- Number of Attributes: 22 (all nominally valued)\n",
    "\n",
    "- Attribute Information: (classes: edible=e, poisonous=p)\n",
    "         1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "         2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "         3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
    "         4. bruises?:                 bruises=t,no=f\n",
    "         5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "         6. gill-attachment:          attached=a,descending=d,free=f,notched=n\n",
    "         7. gill-spacing:             close=c,crowded=w,distant=d\n",
    "         8. gill-size:                broad=b,narrow=n\n",
    "         9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
    "        10. stalk-shape:              enlarging=e,tapering=t\n",
    "        11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
    "        12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "        13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "        14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "        15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "        16. veil-type:                partial=p,universal=u\n",
    "        17. veil-color:               brown=n,orange=o,white=w,yellow=y\n",
    "        18. ring-number:              none=n,one=o,two=t\n",
    "        19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
    "        20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
    "        21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
    "        22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "\n",
    "- Missing Attribute Values: 2480 of them (denoted by \"?\"), all for  attribute #11.\n",
    "\n",
    "- Class Distribution: \n",
    "        --    edible: 4208 (51.8%)\n",
    "        -- poisonous: 3916 (48.2%)\n",
    "        --     total: 8124 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class cap-shape cap-surface cap-color bruises?  odor gill-attachment  \\\n",
      "count   8124      8124        8124      8124     8124  8124            8124   \n",
      "unique     2         6           4        10        2     9               2   \n",
      "top        e         x           y         n        f     n               f   \n",
      "freq    4208      3656        3244      2284     4748  3528            7914   \n",
      "\n",
      "       gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
      "count          8124      8124       8124   ...                       8124   \n",
      "unique            2         2         12   ...                          4   \n",
      "top               c         b          b   ...                          s   \n",
      "freq           6812      5612       1728   ...                       4936   \n",
      "\n",
      "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "count                    8124                   8124      8124       8124   \n",
      "unique                      9                      9         1          4   \n",
      "top                         w                      w         p          w   \n",
      "freq                     4464                   4384      8124       7924   \n",
      "\n",
      "       ring-number ring-type spore-print-color population habitat  \n",
      "count         8124      8124              8124       8124    8124  \n",
      "unique           3         5                 9          6       7  \n",
      "top              o         p                 w          v       d  \n",
      "freq          7488      3968              2388       4040    3148  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./mushrooms.csv')\n",
    "data.columns=columns=['class', 'cap-shape','cap-surface','cap-color','bruises?','odor','gill-attachment','gill-spacing','gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population','habitat']\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises?</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises? odor gill-attachment  \\\n",
       "8119     e         k           s         n        f    n               a   \n",
       "8120     e         x           s         n        f    n               a   \n",
       "8121     e         f           s         n        f    n               a   \n",
       "8122     p         k           y         n        f    y               f   \n",
       "8123     e         x           s         n        f    n               a   \n",
       "\n",
       "     gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
       "8119            c         b          y   ...                          s   \n",
       "8120            c         b          y   ...                          s   \n",
       "8121            c         b          n   ...                          s   \n",
       "8122            c         n          b   ...                          k   \n",
       "8123            c         b          y   ...                          s   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "8119                      o                      o         p          o   \n",
       "8120                      o                      o         p          n   \n",
       "8121                      o                      o         p          o   \n",
       "8122                      w                      w         p          w   \n",
       "8123                      o                      o         p          o   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat  \n",
       "8119           o         p                 b          c       l  \n",
       "8120           o         p                 b          v       l  \n",
       "8121           o         p                 b          c       l  \n",
       "8122           o         e                 w          v       l  \n",
       "8123           o         p                 o          c       l  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (8124L, 22L)  True Class labels dimensions (8124L,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix\n",
    "X=np.asarray(data.ix[:,1:].dropna())\n",
    "Y=np.asarray(data.ix[:,0].dropna())\n",
    "print \" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (5687L, 22L) Training True Class labels dimensions (5687L,)\n",
      " Test Data Set Dimensions= (2437L, 22L) Test True Class labels dimensions (5687L,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier two features\n",
    "#%pdb\n",
    "feat=np.arange(2)\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=7\n",
      "    C(class=e,Purity=0.896551724138)\n",
      "I(Fidx=-1,Score=0.968050015674,Split=[0, ('x', 'c', 'k', 'f')])\n",
      "        C(class=p,Purity=0.575725593668)\n",
      "    I(Fidx=-1,Score=0.965735742057,Split=[1, ('f',)])\n",
      "            C(class=e,Purity=0.655607166556)\n",
      "        I(Fidx=-1,Score=0.916074545985,Split=[0, ('k',)])\n",
      "                C(class=noclass,Purity=-1)\n",
      "            I(Fidx=-1,Score=0.453716339187,Split=[0, 'k'])\n",
      "                    C(class=noclass,Purity=-1)\n",
      "                I(Fidx=-1,Score=0.453716339187,Split=[0, 'k'])\n",
      "                        C(class=noclass,Purity=-1)\n",
      "                    I(Fidx=-1,Score=0.453716339187,Split=[0, 'k'])\n",
      "                        C(class=e,Purity=0.904761904762)\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "Accuracy =  0.981534673779\n"
     ]
    }
   ],
   "source": [
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "383870e8c1eb2fff34369701c8826344",
     "grade": true,
     "grade_id": "acc",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "feat=np.arange(2)\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "\n",
    "\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "\n",
    "assert_greater_equal(acc, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "397b57ec6292e7f23cd31d0ad97103fe",
     "grade": true,
     "grade_id": "acc_all",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain,Ytrain)\n",
    "\n",
    "pclasses=dt.predict(Xtest)\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "\n",
    "assert_greater_equal(acc, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Train on all the features and for both the classes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data Set Dimensions= (5687L, 22L) Training True Class labels dimensions (5687L,)\n",
      " Test Data Set Dimensions= (2437L, 22L) Test True Class labels dimensions (5687L,)\n"
     ]
    }
   ],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "Accuracy =  0.981534673779\n"
     ]
    }
   ],
   "source": [
    "feat=arange(22)#[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5,10)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=2\n",
      "    C(class=p,Purity=1.0)\n",
      "I(Fidx=-1,Score=0.0955909088803,Split=[4, ('a', 'l', 'n')])\n",
      "    C(class=e,Purity=0.972919418758)\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can you conclude ?\n",
    "====================\n",
    "Please write your observation....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Until now we have been splitting the dataset into a training and test set rather randomly and were reporting a rather artifical performance. Now we are going to test our system exhaustively by making use of k-fold [cross validation](http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29). \n",
    "\n",
    "Now go and tune your hyper-parameters (purity, exthreshold) to opitmize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=2\n",
      "    C(class=p,Purity=1.0)\n",
      "I(Fidx=-1,Score=0.0974165640063,Split=[4, ('a', 'l', 'n')])\n",
      "    C(class=e,Purity=0.972273567468)\n",
      "---------------------------------------------------\n",
      "[Info] Fold 1 Accuracy = 0.985228951256\n",
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=2\n",
      "    C(class=p,Purity=1.0)\n",
      "I(Fidx=-1,Score=0.0965663396895,Split=[4, ('a', 'l', 'n')])\n",
      "    C(class=e,Purity=0.972573189522)\n",
      "---------------------------------------------------\n",
      "[Info] Fold 2 Accuracy = 0.984736582964\n",
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=2\n",
      "    C(class=p,Purity=1.0)\n",
      "I(Fidx=-1,Score=0.098264230335,Split=[4, ('a', 'l', 'n')])\n",
      "    C(class=e,Purity=0.971974129966)\n",
      "---------------------------------------------------\n",
      "[Info] Fold 3 Accuracy = 0.985721319547\n",
      "---------------------------------------------------\n",
      " A Decision Tree With Depth=2\n",
      "    C(class=p,Purity=1.0)\n",
      "I(Fidx=-1,Score=0.0974165640063,Split=[4, ('a', 'l', 'n')])\n",
      "    C(class=e,Purity=0.972273567468)\n",
      "---------------------------------------------------\n",
      "[Info] Fold 4 Accuracy = 0.985228951256\n",
      "[0.98522895125553911, 0.98473658296405708, 0.98572131954702114, 0.98522895125553911] \n",
      " Mean Accuracy = 0.985228951256\n"
     ]
    }
   ],
   "source": [
    "# Now lets cross validate for best paramters, and test the result...\n",
    "# We will be training four different models on four different partitions of data set and \n",
    "# then will be reporting the mean accuracy of the four classifiers.\n",
    "\n",
    "nfolds=4 # lets use four folds..\n",
    "folds=t.generate_folds(X,Y,nfolds)\n",
    "features=arange(22)#[0, 1, 2, 3] # features to use for our system\n",
    "#now lets train and test on these folds...\n",
    "totacc=[]\n",
    "for k in range(nfolds):\n",
    "    dt=DecisionTree(0.95,5,7)\n",
    "    dt.train(folds[k][0][:,features],folds[k][1])\n",
    "    pclasses=dt.predict(folds[k][2][:,features])\n",
    "    acc=np.sum(pclasses==folds[k][3])/float(folds[k][3].shape[0])\n",
    "    print dt\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)\n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc, '\\n Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=5.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=6.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=7.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=8.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=9.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=10.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=11.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=12.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=13.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=14.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=15.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=16.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=17.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=18.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=19.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=20.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=21.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=22.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=23.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=24.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.85, Nexample-threshold=25.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=5.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=6.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=7.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=8.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=9.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=10.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=11.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=12.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=13.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=14.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=15.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=16.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=17.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=18.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=19.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=20.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=21.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=22.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=23.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=24.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.86, Nexample-threshold=25.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=5.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=6.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=7.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=8.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=9.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=10.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=11.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=12.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=13.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=14.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=15.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=16.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=17.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=18.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=19.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=20.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=21.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=22.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=23.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=24.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.87, Nexample-threshold=25.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=5.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=6.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=7.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=8.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=9.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=10.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=11.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n",
      "[Info] Fold 3 Accuracy = 0.813392417528\n",
      "[Info] Fold 4 Accuracy = 0.807976366322\n",
      "[0.80059084194977848, 0.81388478581979318, 0.81339241752831115, 0.80797636632200887] \n",
      "Purity=0.88, Nexample-threshold=12.0, Mean Accuracy =0.808961102905\n",
      "[Info] Fold 1 Accuracy = 0.80059084195\n",
      "[Info] Fold 2 Accuracy = 0.81388478582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-1a3cb20223a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpurity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnexamp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#purity[p],nexamp[n])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mpclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpclasses\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-91dde1f538f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[1;31m#Xc=copy.copy(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;31m#Yc=copy.copy(Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-91dde1f538f5>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, X, Y, depth, currNode)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[1;31m#def evaluate_numerical_attribute(self,feat, Y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[1;31m#print \"feat:\",feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmingain_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmpXlidx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtmpXridx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_categorical_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmingain_score\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[1;31m#print \"split:\",split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-91dde1f538f5>\u001b[0m in \u001b[0;36mevaluate_categorical_attribute\u001b[0;34m(self, feat, Y)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                     \u001b[0midxv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0ms_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Shahwaiz\\Anaconda2\\lib\\site-packages\\numpy\\lib\\arraysetops.pyc\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mmask\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now lets cross validate for best paramters, and test the result...\n",
    "# We will be training four different models on four different partitions of data set and \n",
    "# then will be reporting the mean accuracy of the four classifiers.\n",
    "\n",
    "nfolds=4 # lets use four folds..\n",
    "folds=t.generate_folds(X,Y,nfolds)\n",
    "features=[0,1, 2, 3] # features to use for our system\n",
    "#now lets train and test on these folds...\n",
    "\n",
    "#Lets perform the grid search...\n",
    "purity=np.linspace(0.85,0.97,13)\n",
    "nexamp=np.linspace(5,25,21)  \n",
    "\n",
    "params=np.zeros((len(purity),len(nexamp)))\n",
    "                   \n",
    "for p in range(len(purity)):\n",
    "    for n in range(len(nexamp)):\n",
    "        totacc=[]\n",
    "        for k in range(nfolds):\n",
    "            dt=DecisionTree(purity[p],nexamp[n],7)#purity[p],nexamp[n])\n",
    "            dt.train(folds[k][0][:,features],folds[k][1])\n",
    "            pclasses=dt.predict(folds[k][2][:,features])\n",
    "            acc=np.sum(pclasses==folds[k][3])/float(folds[k][3].shape[0])\n",
    "            print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)\n",
    "            totacc.append(acc)\n",
    "        params[p,n]=np.mean(totacc)\n",
    "        print totacc, '\\nPurity={}, Nexample-threshold={}, Mean Accuracy ={}'.format(purity[p],nexamp[n], np.mean(totacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argmax(params), params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
